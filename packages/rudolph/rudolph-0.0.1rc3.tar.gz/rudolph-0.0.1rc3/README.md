[[Paper]]() [[–•–∞–±—Ä]]() [[Model Card]](https://huggingface.co/sberbank-ai/RuDOLPH-350M) [[Colab]](https://colab.research.google.com/drive/1gmTDA13u709OXiAeXWGm7sPixRhEJCga?usp=sharing) [[Kaggle]]()

## <img src="https://raw.githubusercontent.com/sberbank-ai/ru-dolph/master/pics/rudolph.png?token=GHSAT0AAAAAABQH6MST7ZEGAF274DV33K7KYOYRSBQ" height="60"/> RuDOLPH ü¶åüéÑ‚òÉÔ∏è

*One Hyper-Modal Transformer can be creative as DALL-E and smart as CLIP*

---

**Ru**ssian **D**iffusion **O**n **L**anguage **P**icture **H**yper-modality (RuDOLPH) is a fast 
and light text-image-text transformer (350M GPT-3) designed for a quick and easy fine-tuning setup 
for the solution of various tasks: from generating images by text description and image classification 
to visual question answering and more. This model demonstrates the power of Hyper-modality Transformers.

*(!!!) Hyper-modality means generalized multi-modal, e.g., model that consists of two multi-modal parts: text-2-image and image-2-text becomes text and image hyper-modality model*


![](./pics/scheme.png)

# Sparse Attention Mask
`row - col - row - [last] conv`

![](./pics/attention_masks.png)

# Models
+ [350M (RuDOLPH)](https://huggingface.co/sberbank-ai/RuDOLPH-350M)
+ 1.3B (In Progress)
+ 4B (In Progress)


![](./pics/high_res.png)

# Installing
```
pip install rudolph==0.0.1rc3
```

# Usage
### Init models
```python
from rudalle import get_tokenizer, get_vae
from rudalle.utils import seed_everything
from rudalle.image_prompts import ImagePrompts

from rudolph.model import get_rudolph_model
from rudolph.pipelines import zs_clf, generate_codebooks, self_reranking_by_image, self_reranking_by_text, show, generate_captions, generate_texts
from rudolph import utils

device = 'cuda'
model = get_rudolph_model('350M', fp16=True, device=device)
model.to(device);
tokenizer = get_tokenizer()
vae = get_vae(dwt=False).to(device)
```

### Setup for Fast Image Generation

```python
text = '—Ä–∏—Å—É–Ω–æ–∫ –∫–æ—Ç–∞'
bs, images_num = 48, 48
top_k, top_p = 512, 0.9
with torch.no_grad():
    codebooks = generate_codebooks(text, tokenizer, model, top_k=top_k, images_num=images_num, top_p=top_p, bs=bs)
    ppl_text, ppl_image = self_reranking_by_text(text, codebooks, tokenizer, model, bs=bs)
    images = vae.decode(codebooks[ppl_text.argsort()[:4]])
images = torchvision.utils.make_grid(images, nrow=2)
img = torchvision.transforms.functional.to_pil_image(images)
img
```
![](./pics/pipelines/cat_drawing.png)


### Text Generation
```python
generate_texts(
    tokenizer,
    model,
    template='–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ ',
    top_k=32, top_p=0.6, texts_num=32, bs=32, seed=42
)[:8]

[{'text': '–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ –≤–∏–¥ –Ω–∞ –∑–∞–∫–∞—Ç —Å –≤–µ—Ä—à–∏–Ω—ã –≥–æ—Ä—ã –∏ –ª–µ—Å–∞ –Ω–∞ –æ—Å—Ç—Ä–æ–≤–µ –º–∞–≤—Ä–∏–∫–∏–π', 'ppl': 125.21},
 {'text': '–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ —Å –ª–µ—Å–æ–º –∏ –æ–∑–µ—Ä–æ–º –≤ —Ñ–∏–Ω–ª—è–Ω–¥–∏–∏ - —Ñ–∏–Ω–ª—è–Ω–¥–∏—è', 'ppl': 146.34},
 {'text': '–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ —Å –≥–æ—Ä–∞–º–∏ –∏ –ª–µ—Å–∞–º–∏ –≤ —Ç—É–º–∞–Ω–µ - –≥–æ—Ä—ã –≤ —Ç—É–º–∞–Ω–µ', 'ppl': 147.4},
 {'text': '–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ —Å –≥–æ—Ä–Ω—ã–º —Ö—Ä–µ–±—Ç–æ–º –Ω–∞ –∑–∞–¥–Ω–µ–º –ø–ª–∞–Ω–µ', 'ppl': 183.2},
 {'text': '–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ —Å –æ–∑–µ—Ä–æ–º –∏ –≥–æ—Ä–Ω—ã–º —Ö—Ä–µ–±—Ç–æ–º', 'ppl': 199.13},
 {'text': '–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ —Å –≥–æ—Ä–Ω—ã–º —Ö—Ä–µ–±—Ç–æ–º –∏ —Ä–µ–∫–æ–π', 'ppl': 202.48},
 {'text': '–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ –Ω–∞ –∑–∞–∫–∞—Ç–µ –≤ —Ç–æ—Å–∫–∞–Ω–µ, –∏—Ç–∞–ª–∏—è', 'ppl': 220.98},
 {'text': '–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ –≤–∏–¥ –Ω–∞ –º–æ—Ä–µ –≤ —Å–æ–ª–Ω–µ—á–Ω—ã–π –¥–µ–Ω—å', 'ppl': 223.37}]
```

### Image Generation + Self Reranking
```python
text = '–∫—Ä–∞—Å–∏–≤—ã–π –ø–µ–π–∑–∞–∂ —Å –æ–∑–µ—Ä–æ–º –∏ –ª–µ—Å–æ–º –Ω–∞ –∑–∞–¥–Ω–µ–º –ø–ª–∞–Ω–µ'
images_num = 256
seed_everything(42)
codebooks = []
for top_k, top_p, images_num in [
    (2048, 0.99, images_num),
    (1024, 0.99, images_num),
    (1024, 0.98, images_num),
]:
    codebooks.append(generate_codebooks(text, tokenizer, model, top_k=top_k, images_num=images_num, top_p=top_p, bs=32))

codebooks = torch.cat(codebooks)

ppl_text, ppl_image = self_reranking_by_text(text, codebooks, tokenizer, model, bs=32)
with torch.no_grad():
    images = vae.decode(codebooks[ppl_text.argsort()[:16]])

pil_images = utils.torch_tensors_to_pil_list(images)
show(pil_images, 8)
```
![](./pics/pipelines/lake.png)


```python
text = '–∑–∏–º–Ω–µ–µ –≤—Ä–µ–º—è –≥–æ–¥–∞'

ppl_text, ppl_image = self_reranking_by_text(text, codebooks, tokenizer, model, bs=32)
with torch.no_grad():
    images = vae.decode(codebooks[ppl_text.argsort()[:16]])

pil_images = utils.torch_tensors_to_pil_list(images)
show(pil_images, 8)
```
![](./pics/pipelines/lake_winter.png)


```python
text = '–Ω–æ—á–Ω–æ–µ –≤—Ä–µ–º—è —Å—É—Ç–æ–∫'

ppl_text, ppl_image = self_reranking_by_text(text, codebooks, tokenizer, model, bs=32)
with torch.no_grad():
    images = vae.decode(codebooks[ppl_text.argsort()[:16]])

pil_images = utils.torch_tensors_to_pil_list(images)
show(pil_images, 8)
```
![](./pics/pipelines/lake_night.png)


### Image Prompt (like Inpainting)
![](pics/pipelines/lake_image_prompt.png)
```python
text = '–ª–æ–¥–∫–∞ —Å –∞–ª—ã–º–∏ –ø–∞—Ä—É—Å–∞–º–∏'

images_num = 1024
bs = 32

borders = {'up': 6, 'left': 4, 'right': 6, 'down': 2}
image_prompts = ImagePrompts(pil_img, borders, vae, device, crop_first=True)

seed_everything(42)
codebooks = []
for top_k, top_p, images_num in [
    (1024, 0.99, images_num),
]:
    codebooks.append(
        generate_codebooks(text, tokenizer, model, top_k=top_k, images_num=images_num, top_p=top_p, bs=bs, image_prompts=image_prompts)
    )

codebooks = torch.cat(codebooks)

ppl_text, ppl_image = self_reranking_by_text(
    text,
    codebooks,
    tokenizer,
    model,
    bs=bs,
)
with torch.no_grad():
    images = vae.decode(codebooks[ppl_text.argsort()[:16]])

pil_images = utils.torch_tensors_to_pil_list(images)
show(pil_images, 8)
```
![](./pics/pipelines/lake_ship.png)

### Diffusion (TODO, see [Colab](https://colab.research.google.com/drive/1gmTDA13u709OXiAeXWGm7sPixRhEJCga?usp=sharing))

### Image Captioning + Self Reranking

```python
texts = generate_captions(pil_img, tokenizer, model, vae, template='–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ ', top_k=16, captions_num=128, bs=32, top_p=0.6, temperature=0.8, seed=43)
ppl_text, ppl_image = self_reranking_by_image(texts, pil_img, tokenizer, model, vae, bs=32, seed=42)
for idx in ppl_image.argsort()[:8]:
    print(f'-{texts[idx]}')
```

![](./pics/pipelines/final_lake_ship.png)
```python
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∫–æ—Ä–∞–±–ª–∏–∫ –≤ –ª–µ—Å—É
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ –∫—Ä–∞—Å–∏–≤—É—é –∫–∞—Ä—Ç–∏–Ω–∫—É –Ω–∞ —Ç–µ–ª–µ—Ñ–æ–Ω –Ω–∞ –∑–∞—Å—Ç–∞–≤–∫—É
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –º–æ—Ä–µ —Å –¥–æ–º–∏–∫–æ–º
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∫–∞–∫ –≤—ã–≥–ª—è–¥–∏—Ç —Å–∞–º—ã–π –∫—Ä–∞—Å–∏–≤—ã–π –º–æ—Å—Ç –≤ –º–∏—Ä–µ
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –≤ —Ö–æ—Ä–æ—à–µ–º –∫–∞—á–µ—Å—Ç–≤–µ
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –æ–±–æ–∏ –Ω–∞ —Ä–∞–±–æ—á–∏–π —Å—Ç–æ–ª
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –º–æ–∂–Ω–æ —Å–∫–∞—á–∞—Ç—å –æ–±–æ–∏ –Ω–∞ —Ä–∞–±–æ—á–∏–π —Å—Ç–æ–ª
```

![](./pics/pipelines/captioning_dog.png)
```python
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω –æ—Ö–æ—Ç–Ω–∏—á–∏–π —Å–ø–∞–Ω–∏–µ–ª—å
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ —Å–æ–±–∞–∫–∞ –±–æ–∫—Å–µ—Ä
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ —Å–æ–±–∞–∫–∞ –ø–æ—Ö–æ–∂–∞ –Ω–∞ —Å—Ç–∞—Ñ—Ñ–æ—Ä–¥–∞
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω –±–µ–ª—ã–π –±–∏–≥–ª—å
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ —Å–æ–±–∞–∫–∞ —Å –±–æ–ª—å—à–∏–º –Ω–æ—Å–æ–º
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ —Å–æ–±–∞–∫–∞ –ø–æ—Ö–æ–∂–∞—è –Ω–∞ —Å—Ç–∞—Ñ—Ñ–æ—Ä–¥–∞
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∞ —Å–æ–±–∞–∫–∞ —Å –±–æ–ª—å—à–∏–º –Ω–æ—Å–æ–º
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ —Å–æ–±–∞–∫–∞ –ø–æ—Ö–æ–∂–∞—è –Ω–∞ —Å—Ç–∞—Ñ—Ñ–æ—Ä–¥—à–∏—Ä—Å–∫–∏–π —Ç–µ—Ä—å–µ—Ä
```

![](./pics/pipelines/captioning_street.png)
```python
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∞ –º–Ω–æ–≥–æ—ç—Ç–∞–∂–∫–∞
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω—ã –¥–≤–∞ —á–µ–ª–æ–≤–µ–∫–∞ –≤ –∑–¥–∞–Ω–∏–∏
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω—ã –¥–æ–º–∞
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω –¥–æ–º —Å –ø—Ä–∏–≤–∏–¥–µ–Ω–∏—è–º–∏
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∞ –≥–æ—Å—Ç–∏–Ω–∏—Ü–∞
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω—ã –¥–≤–µ –∫–≤–∞—Ä—Ç–∏—Ä—ã
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∑–¥–∞–Ω–∏–µ –≤ —Ü–µ–Ω—Ç—Ä–µ –≥–æ—Ä–æ–¥–∞
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω –º–Ω–æ–≥–æ–∫–≤–∞—Ä—Ç–∏—Ä–Ω—ã–π –¥–æ–º
```

![](./pics/pipelines/captioning_moto.png)
```python
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ —è –≤–∏–∂—É –º–æ—Ç–æ—Ü–∏–∫–ª
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ —è —Ö–æ—á—É –≤ —Ç–∞–¥–∂–∏–∫–∏—Å—Ç–∞–Ω
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ —è –≤–∏–∂—É –¥–≤—É—Ö—ç—Ç–∞–∂–Ω—É—é –∫—Ä–∞—Å–∏–≤—É—é –∫—Ä–∞—Å–∏–≤—É—é –≤–µ—Ä–∞–Ω–¥—É —Å –≤–µ–ª–æ—Å–∏–ø–µ–¥–æ–º –∏ –≤–µ–ª–æ—Å–∏–ø–µ–¥–æ–º
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∞ –º–æ—Ç–æ—Ü–∏–∫–ª
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ —è –≤–∏–∂—É –¥–≤—É—Ö—ç—Ç–∞–∂–Ω—ã–π –≤–µ–ª–æ—Å–∏–ø–µ–¥
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ —è –≤–∏–∂—É –¥–≤—É—Ö—ç—Ç–∞–∂–Ω—É—é –∏–∑–±—É —Å –≤–µ–ª–æ—Å–∏–ø–µ–¥–æ–º
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ —è —Ö–æ—á—É –ø–æ–∫—Ä–∞—Å–∏—Ç—å —Å—Ç–∞—Ä—ã–π –¥–µ—Ä–µ–≤—è–Ω–Ω—ã–π –¥–æ–º
-–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∞ –º–∞—à–∏–Ω–∞ —Å –º–æ—Ç–æ—Ü–∏–∫–ª–æ–º
```

### Zero-Shot Image Classification using PPL
```python
import base64
import requests
from PIL import Image
from io import BytesIO

bs4_urls = requests.get('https://raw.githubusercontent.com/sberbank-ai/ru-dolph/master/pics/pipelines/cats_vs_dogs_bs4.json').json()

f, ax = plt.subplots(2,4, figsize=(12,6))

for i, bs4_url in enumerate(bs4_urls):
    pil_img = Image.open(BytesIO(base64.b64decode(bs4_url)))
    
    classes = ['–∫–æ—à–∫–∞', '—Å–æ–±–∞–∫–∞']
    preds = zs_clf(
        pil_img, 
        classes,
        model, 
        tokenizer,
        vae,
        template = '{}', 
    )
    ax[i//4, i%4].imshow(pil_img)
    ax[i//4, i%4].set_title(preds['class'])
```
![](./pics/pipelines/zs_clf.png)

### Linear Probe (TODO, see [Colab](https://colab.research.google.com/drive/1gmTDA13u709OXiAeXWGm7sPixRhEJCga?usp=sharing))

# Authors: 

+ Alex Shonenkov: [Github](https://github.com/shonenkov), [Kaggle GM](https://www.kaggle.com/shonenkov)
+ Michael Konstantinov: [Mishin Learning](https://t.me/mishin_learning), [Transformer Community](https://transformer.community/)

<img src='https://habrastorage.org/webt/2w/5k/2r/2w5k2reyf6yqa4s7ywmmioaaieg.png' alt="Drawing" width="200" />  <img src='https://habrastorage.org/webt/eq/ft/g3/eqftg3_8l1b_fpimhiof7knytzk.png' alt="Drawing" width="200" />

# Citation

```
@article{shonenkov2022ruDolph,
  title         = {RuDOLPH: One Hyper-Modal Transformer can be creative as DALL-E and smart as CLIP},
  author        = {Alex Shonenkov and Michael Konstantinov},
  year          = {2022},
  eprint        = {...},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CL}
}
```

```
@misc{github2022ruDolph,
  title         = {RuDOLPH: One Hyper-Modal Transformer can be creative as DALL-E and smart as CLIP},
  author        = {Alex Shonenkov and Michael Konstantinov},
  year          = {2022},
  howpublished  = {\url{https://github.com/sberbank-ai/ru-dolph}},
}
```

# Supported by

[<img src="https://raw.githubusercontent.com/sberbank-ai/ru-dolph/master/pics/logo/sberai-logo.png" height="115"/>](https://github.com/sberbank-ai) \
[<img src="https://raw.githubusercontent.com/sberbank-ai/ru-dolph/master/pics/logo/sberdevices-logo.png" height="40"/>](https://sberdevices.ru)

[<img src="https://raw.githubusercontent.com/sberbank-ai/ru-dolph/master/pics/logo/sbercloud-logo.png" height="80"/>](https://sbercloud.ru/) \
[<img src="https://raw.githubusercontent.com/sberbank-ai/ru-dolph/master/pics/logo/airi-logo.png" height="50"/>](https://airi.net)
